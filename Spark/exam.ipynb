{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://DESKTOP-UCGP8OJ:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.4</code></dd>\n              <dt>Master</dt>\n                <dd><code>local[*]</code></dd>\n              <dt>AppName</dt>\n                <dd><code>pyspark-shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ",
      "text/plain": "<pyspark.sql.session.SparkSession at 0x28f060db898>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc = SparkContext()\n",
    "sc.addPyFile(\"graphframes-0.7.0-spark2.4-s_2.11.jar\")\n",
    "\n",
    "from graphframes import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0\n"
    }
   ],
   "source": [
    "sum = 0\n",
    "rdd = sc.parallelize(range(20),2) \n",
    "def update_sum(x):\n",
    "    global sum\n",
    "    sum += x\n",
    "rdd.foreach(update_sum)\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "190\n"
    }
   ],
   "source": [
    "sum = sc.accumulator(0)\n",
    "rdd = sc.parallelize(range(20),2) \n",
    "def update_sum(x):\n",
    "    global sum\n",
    "    sum += x\n",
    "rdd.foreach(update_sum)\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "4\n"
    }
   ],
   "source": [
    "A = sc.parallelize(range(1, 1000))\n",
    "t = 100\n",
    "B = A.filter(lambda x: x * x > t )\n",
    "B.cache()\n",
    "t = 200\n",
    "C = B.filter(lambda x: x * x < t )\n",
    "print (C.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[8, 4, 6, 5]\n"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([5,0,0,3])\n",
    "rdd2 = sc.parallelize([3,4,6,2])\n",
    "\n",
    "\n",
    "def ele_wise_add(rdd1, rdd2): \n",
    "    return rdd1.zip(rdd2).map(lambda x: x[0] + x[1])\n",
    "\n",
    "rdd3 = ele_wise_add(rdd1, rdd2)\n",
    "print(rdd3.collect())\n",
    "# Expected output: [8,4,6,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphframes import *\n",
    "\n",
    "# Vertices DataFrame\n",
    "v = spark.createDataFrame([\n",
    " (\"a\", \"Alice\", 34),\n",
    " (\"b\", \"Bob\", 36),\n",
    " (\"c\", \"Charlie\", 37),\n",
    " (\"d\", \"David\", 29),\n",
    " (\"e\", \"Esther\", 32),\n",
    " (\"f\", \"Fanny\", 38),\n",
    " (\"g\", \"Gabby\", 60)\n",
    "], [\"id\", \"name\", \"age\"])\n",
    "\n",
    "# Edges DataFrame\n",
    "e = spark.createDataFrame([\n",
    " (\"a\", \"b\", \"follow\"),\n",
    " (\"c\", \"a\", \"friend\"),\n",
    " (\"b\", \"c\", \"follow\"),\n",
    " (\"d\", \"a\", \"follow\"),\n",
    " (\"f\", \"c\", \"follow\"),\n",
    " (\"f\", \"d\", \"follow\"),\n",
    " (\"f\", \"b\", \"follow\"),\n",
    " (\"c\", \"d\", \"follow\"),\n",
    " (\"g\", \"a\", \"friend\"),\n",
    " (\"g\", \"d\", \"friend\"),\n",
    " (\"g\", \"c\", \"friend\"),\n",
    " (\"e\", \"a\", \"follow\"),\n",
    " (\"e\", \"d\", \"follow\")\n",
    "], [\"src\", \"dst\", \"relationship\"])\n",
    "# Create a GraphFrame\n",
    "g = GraphFrame(v, e)\n",
    "\n",
    "# FILL IN YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+-----+\n| name|\n+-----+\n|Fanny|\n+-----+\nonly showing top 1 row\n\n"
    }
   ],
   "source": [
    "e2 = e.filter(\"relationship = 'follow'\")\n",
    "g2 = GraphFrame(v, e2)\n",
    "zombies = g2.find(\"(a)-[]->(b); !(b)-[]->(a)\") \\\n",
    "            .groupBy(\"a\") \\\n",
    "            .count() \\\n",
    "            .orderBy('count', ascending = False) \\\n",
    "            .select(\"a.name\")\n",
    "\n",
    "zombies.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "+---+---+---+\n|  x|  y|  z|\n+---+---+---+\n|  1|  2|  3|\n+---+---+---+\n\n"
    }
   ],
   "source": [
    "e = sc.parallelize([(1,2),(1,3),(1,4),(2,3),(3,1)]).toDF([\"src\",\"dst\"])\n",
    "\n",
    "e1 = e.withColumnRenamed('src', 'x').withColumnRenamed('dst','y')\n",
    "e2 = e.withColumnRenamed('src', 'y1').withColumnRenamed('dst','z')\n",
    "\n",
    "e3 = e.withColumnRenamed('src', 'y').withColumnRenamed('dst','y1')\n",
    "\n",
    "result = e1.join(e3, 'y').join(e2, 'y1') \\\n",
    "                         .withColumnRenamed('z', 'x1') \\\n",
    "                         .withColumnRenamed('y1', 'z') \\\n",
    "                         .filter(\"x == x1 AND x < y AND y < z\") \n",
    "\n",
    "result.select('x','y','z').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[67, 56, 47, 34, 89, 74, 44, 43, 85, 26, 12, 8]\n[89, 85, 74, 67]\n"
    }
   ],
   "source": [
    "import heapq\n",
    "\n",
    "# Example to illustrate: We have 15 numbers, 3 works(3 partitions) to find 4 largest numbers\n",
    "data = [34, 67, 21, 56, 47, 89, 12, 44, 74, 43, 26, 12, 5, 8, 85]\n",
    "# number of works = 3 \n",
    "A = sc.parallelize(data, 3)\n",
    "\n",
    "\n",
    "def find_k_max(iterator):\n",
    "    return heapq.nlargest(4, iterator)\n",
    "\n",
    "# Find the k largestÂ  integers in each partition and collect the result\n",
    "collection = A.mapPartitions(find_k_max).collect()\n",
    "print(collection)\n",
    "# Calculate the k largest integers in the collection\n",
    "result = heapq.nlargest(4, collection)\n",
    "\n",
    "print(result)"
   ]
  }
 ]
}